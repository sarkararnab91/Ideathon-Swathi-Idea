{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf\n",
    "#!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import PyPDF2\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import streamlit as st\n",
    "from utils import get_table_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to create 10-20 multiple choice questions from a given piece of text.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"001_ed_tech_quiz\", \"Neural_Network_Excellent_Explanation.pdf\")\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Neural_Network_Excellent_Explanation.pdf\")\n",
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\f\f\fIs there a simple algorithm for intelligence?\n",
      "behind the brain‚Äôs architecture.\n",
      "In the last few paragraphs I‚Äôve ignored the fact that 125 million bits merely quantiÔ¨Åes\n",
      "the genetic difference between human and chimp brains. Not all our brain function is\n",
      "due to those 125 million bits. Chimps are remarkable thinkers in their own right. Maybe\n",
      "the key to intelligence lies mostly in the mental abilities (and genetic information) that\n",
      "chimps and humans have in common. If this is correct, then human brains might be just a\n",
      "minor upgrade to chimpanzee brains, at least in terms of the complexity of the underlying\n",
      "principles. Despite the conventional human chauvinism about our unique capabilities, \n"
     ]
    }
   ],
   "source": [
    "print(docs[234].page_content[:700])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing: Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits[234].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Neural_Network_Excellent_Explanation.pdf',\n",
       " 'page': 72,\n",
       " 'start_index': 794}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[234].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing: Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to index our text chunks so that we can search over them at runtime. The most common way to do this is to embed the contents of each document split and insert these embeddings into a vector database (or vector store). When we want to search over our splits, we take a text search query, embed it, and perform some sort of ‚Äúsimilarity‚Äù search to identify the stored splits with the most similar embeddings to our query embedding. The simplest similarity measure is cosine similarity ‚Äî we measure the cosine of the angle between each pair of embeddings (which are high dimensional vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval: Retrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\f\f\fHow the backpropagation algorithm works\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is back propagation?\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_template = \"\"\"\n",
    "Context: {context}\n",
    "You are an expert MCQ maker on the given {topic}. Given the above text, it is your job to\\\n",
    "create a quiz of {number} multiple choice questions for professionals in {difficulty} difficulty level\n",
    "Make sure that questions are not repeated and check all the questions to be conforming to the text as well.\n",
    "Make sure to format your response like the RESPONSE_JSON below and use it as a guide.\\\n",
    "Ensure to make the {number} MCQs.\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"topic\", \"difficulty\", \"number\", \"response_json\"],\n",
    "    template=quiz_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"no\": \"1\",\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"no\": \"2\",\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"no\": \"3\",\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RAG Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(\n",
    "    llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True\n",
    ")\n",
    "# This is the overall chain where we run these two chains in sequence.\n",
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[quiz_chain],\n",
    "    input_variables=[\"context\", \"topic\", \"difficulty\", \"number\", \"response_json\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"quiz\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq_count = 3\n",
    "mcq_topic = \"Back propagation\"\n",
    "difficulty = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnab\\Desktop\\Data_Science\\Ideathon_TechM\\langchain-series\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Context: first=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000028CFDB201D0>, search_kwargs={'k': 3}) last=RunnableLambda(format_docs)\n",
      "You are an expert MCQ maker on the given Back propagation. Given the above text, it is your job tocreate a quiz of 3 multiple choice questions for professionals in simple difficulty level\n",
      "Make sure that questions are not repeated and check all the questions to be conforming to the text as well.\n",
      "Make sure to format your response like the RESPONSE_JSON below and use it as a guide.Ensure to make the 3 MCQs.\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# count tokens and cost of api call\n",
    "with get_openai_callback() as cb:\n",
    "        response = generate_evaluate_chain(\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"topic\" : mcq_topic,\n",
    "            \"number\": mcq_count,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON),\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 611\n",
      "Prompt Tokens: 330\n",
      "Completion Tokens: 281\n",
      "Total Cost (USD): $0.0010570000000000002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "print(f\"Total Cost (USD): ${cb.total_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Extract quiz data from the response\n",
    "quiz = response.get(\"quiz\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"no\": \"1\", \"mcq\": \"What is Back propagation?\", \"options\": {\"a\": \"A machine learning algorithm used to train neural networks\", \"b\": \"A technique used to calculate the gradient of a loss function with respect to the weights of a neural network\", \"c\": \"A method for updating the weights of a neural network based on the error between the predicted and actual outputs\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"2\": {\"no\": \"2\", \"mcq\": \"What is the purpose of Back propagation?\", \"options\": {\"a\": \"To minimize the error between the predicted and actual outputs of a neural network\", \"b\": \"To maximize the accuracy of a neural network\", \"c\": \"To calculate the gradient of a loss function with respect to the weights of a neural network\", \"d\": \"To update the weights of a neural network\"}, \"correct\": \"a\"}, \"3\": {\"no\": \"3\", \"mcq\": \"Which of the following is true about Back propagation?\", \"options\": {\"a\": \"It is only used in supervised learning\", \"b\": \"It is an unsupervised learning algorithm\", \"c\": \"It is used to train deep learning models\", \"d\": \"It is a reinforcement learning technique\"}, \"correct\": \"c\"}}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if quiz is not None:\n",
    "    table_data = get_table_data(quiz)\n",
    "    if table_data is not None:\n",
    "        df = pd.DataFrame(table_data)\n",
    "        df.index = df.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"ü¶ú‚õìÔ∏è Quiz Generation for Educational Content\")\n",
    "\n",
    "# Create a form using st.form\n",
    "with st.form(\"user_inputs\"):\n",
    "    # File upload\n",
    "    #uploaded_file = st.file_uploader(\"Upload a pdf or text file\")\n",
    "\n",
    "    # Input fields\n",
    "    mcq_count = st.number_input(\"No of MCQs\", min_value=3, max_value=20,placeholder=3)\n",
    "    topic = st.text_input(\"Provide a topic\", max_chars=100,placeholder=\"backpropagation algorithm\")\n",
    "    difficulty = st.text_input(\"Provide Quiz difficulty\", max_chars=100, placeholder=\"simple or complex\")\n",
    "\n",
    "    button = st.form_submit_button(\"Create quiz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_question(index, row):\n",
    "    st.subheader(f\"Q{index + 1}: {row['Questions']}\")\n",
    "    selected_option = st.radio(\"Choose your answer:\", row['Choices'], index=0)\n",
    "    return selected_option\n",
    "\n",
    "def main(df):\n",
    "    st.title(\"MCQ Quiz App\")\n",
    "\n",
    "    # Load data\n",
    "    df = df.copy()\n",
    "\n",
    "    # Display questions\n",
    "    user_answers = []\n",
    "    for index, row in df.iterrows():\n",
    "        user_answer = display_question(index, row)\n",
    "        user_answers.append(user_answer)\n",
    "\n",
    "    # Submit button\n",
    "    if st.button(\"Submit\"):\n",
    "        # Calculate score\n",
    "        correct_answers = df['Correct_Answer'].tolist()\n",
    "        score = sum(user_answer == correct_answer for user_answer, correct_answer in zip(user_answers, correct_answers))\n",
    "\n",
    "        # Display score\n",
    "        st.success(f\"Your Score: {score}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the button is clicked and all fields have inputs\n",
    "if button and uploaded_file is not None and topic and mcq_count and difficulty:\n",
    "    with st.spinner(\"Loading...\"):\n",
    "        try:\n",
    "            text = parse_file(uploaded_file)\n",
    "\n",
    "            # count tokens and cost of api call\n",
    "            with get_openai_callback() as cb:\n",
    "                response = generate_evaluate_chain(\n",
    "                    {\n",
    "                        \"text\": text,\n",
    "                        \"number\": mcq_count,\n",
    "                        \"grade\": grade,\n",
    "                        \"tone\": tone,\n",
    "                        \"response_json\": json.dumps(RESPONSE_JSON),\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            traceback.print_exception(type(e), e, e.__traceback__)\n",
    "            st.error(\"Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
